{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ea35a9",
   "metadata": {},
   "source": [
    "1. URL 관련 특성 추출 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8af915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import socket\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "\n",
    "def url_len(url):\n",
    "    return len(url)\n",
    "\n",
    "def url_num_hyphens_dom(url):\n",
    "    return urlparse(url).netloc.count('-')\n",
    "\n",
    "def url_num_dom_token(url):\n",
    "    return len(urlparse(url).netloc.split('.'))\n",
    "\n",
    "def url_path_len(url):\n",
    "    return len(urlparse(url).path)\n",
    "\n",
    "def url_filename_len(url):\n",
    "    return len(urlparse(url).path.split('/')[-1])\n",
    "\n",
    "def url_longest_dom_token_len(url):\n",
    "    tokens = urlparse(url).netloc.split('.')\n",
    "    return max(len(t) for t in tokens)\n",
    "\n",
    "def url_average_dom_token_len(url):\n",
    "    tokens = urlparse(url).netloc.split('.')\n",
    "    return sum(len(t) for t in tokens) / len(tokens)\n",
    "\n",
    "def url_domain_len(url):\n",
    "    return len(urlparse(url).netloc)\n",
    "\n",
    "def url_hostname_len(url):\n",
    "    return len(urlparse(url).hostname or '')\n",
    "\n",
    "def url_num_dots(url):\n",
    "    return url.count('.')\n",
    "\n",
    "def url_num_underscores(url):\n",
    "    return url.count('_')\n",
    "\n",
    "def url_num_equals(url):\n",
    "    return url.count('=')\n",
    "\n",
    "def url_num_slashes(url):\n",
    "    return url.count('/')\n",
    "\n",
    "def url_num_dash(url):\n",
    "    return url.count('-')\n",
    "\n",
    "def url_num_semicolon(url):\n",
    "    return url.count(';')\n",
    "\n",
    "def url_num_at(url):\n",
    "    return url.count('@')\n",
    "\n",
    "def url_num_percent(url):\n",
    "    return url.count('%')\n",
    "\n",
    "def url_num_plus(url):\n",
    "    return url.count('+')\n",
    "\n",
    "def url_query_len(url):\n",
    "    return len(urlparse(url).query)\n",
    "\n",
    "def url_num_query_para(url):\n",
    "    return len(urlparse(url).query.split('&')) if urlparse(url).query else 0\n",
    "\n",
    "def url_ip_present(url):\n",
    "    try:\n",
    "        host = urlparse(url).netloc\n",
    "        socket.inet_aton(host)\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def url_entropy(url):\n",
    "    prob = [n / len(url) for n in Counter(url).values()]\n",
    "    return -sum(p * math.log2(p) for p in prob)\n",
    "\n",
    "def url_count_consonants(url):\n",
    "    consonants = set(\"bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ\")\n",
    "    return sum(1 for c in url if c in consonants)\n",
    "\n",
    "def url_num_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "def url_chinese_present(url):\n",
    "    \"\"\"URL에 중국어(한자) 문자가 포함되어 있는지 확인\"\"\"\n",
    "    for char in url:\n",
    "        if '\\u4e00' <= char <= '\\u9fff':  # 한자 유니코드 범위\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def url_port(url):\n",
    "    return urlparse(url).port or 80  # 기본 포트 80\n",
    "\n",
    "def url_has_https(url):\n",
    "    \"\"\"HTTPS 사용 여부\"\"\"\n",
    "    return int(urlparse(url).scheme == 'https')\n",
    "\n",
    "def url_has_ip_address(url):\n",
    "    \"\"\"도메인 대신 IP 사용 여부\"\"\"\n",
    "    import re\n",
    "    host = urlparse(url).netloc\n",
    "    # IPv4 정규식\n",
    "    return int(bool(re.match(r\"^\\d{1,3}(\\.\\d{1,3}){3}$\", host)))\n",
    "\n",
    "def url_num_subdomains(url):\n",
    "    \"\"\"서브도메인 개수\"\"\"\n",
    "    tokens = urlparse(url).hostname.split('.') if urlparse(url).hostname else []\n",
    "    # 일반적으로 도메인+TLD를 제외한 나머지가 서브도메인\n",
    "    return max(len(tokens) - 2, 0)\n",
    "\n",
    "def url_has_suspicious_words(url):\n",
    "    \"\"\"의심 단어 포함 여부 (예: login, verify, update 등)\"\"\"\n",
    "    suspicious = ['login', 'verify', 'update', 'secure', 'account', 'bank', 'signin', 'wp-admin']\n",
    "    return int(any(word in url.lower() for word in suspicious))\n",
    "\n",
    "def url_length_category(url):\n",
    "    \"\"\"URL 길이 구간화 (짧음/보통/김)\"\"\"\n",
    "    l = len(url)\n",
    "    if l < 54:\n",
    "        return 0  # 짧음\n",
    "    elif l < 75:\n",
    "        return 1  # 보통\n",
    "    else:\n",
    "        return 2  # 김\n",
    "\n",
    "def url_has_port_in_url(url):\n",
    "    \"\"\"URL에 포트 명시 여부\"\"\"\n",
    "    return int(':' in urlparse(url).netloc)\n",
    "\n",
    "def url_num_special_chars(url):\n",
    "    \"\"\"특수문자 개수\"\"\"\n",
    "    special_chars = set('!#$%^&*()[]{};:,<>?\\\\|`~')\n",
    "    return sum(1 for c in url if c in special_chars)\n",
    "\n",
    "def url_num_params(url):\n",
    "    \"\"\"URL 파라미터 개수\"\"\"\n",
    "    return urlparse(url).query.count('=')  # 파라미터 개수\n",
    "\n",
    "def url_num_fragments(url):\n",
    "    \"\"\"URL에 #fragment 개수\"\"\"\n",
    "    return url.count('#')\n",
    "\n",
    "def url_starts_with_www(url):\n",
    "    \"\"\"www로 시작하는지 여부\"\"\"\n",
    "    return int(urlparse(url).netloc.startswith('www.'))\n",
    "\n",
    "def url_is_shortened(url):\n",
    "    \"\"\"단축 URL 여부 (일부 유명 단축 도메인 포함)\"\"\"\n",
    "    shorteners = ['bit.ly', 'goo.gl', 't.co', 'tinyurl.com', 'ow.ly', 'is.gd', 'buff.ly', 'adf.ly']\n",
    "    netloc = urlparse(url).netloc.lower()\n",
    "    return int(any(s in netloc for s in shorteners))\n",
    "\n",
    "def url_has_email(url):\n",
    "    \"\"\"URL에 이메일 주소 포함 여부\"\"\"\n",
    "    return int(bool(re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", url)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba5539",
   "metadata": {},
   "source": [
    "✅ 2. HTML 태그 관련 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e73fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bs4\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_num_tags(html, tag):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return len(soup.find_all(tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783289ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_features(url):\n",
    "    return {\n",
    "        \"url_len\": url_len(url),\n",
    "        \"url_num_hyphens_dom\": url_num_hyphens_dom(url),\n",
    "        \"url_num_dom_token\": url_num_dom_token(url),\n",
    "        \"url_path_len\": url_path_len(url),\n",
    "        \"url_filename_len\": url_filename_len(url),\n",
    "        \"url_longest_dom_token_len\": url_longest_dom_token_len(url),\n",
    "        \"url_average_dom_token_len\": url_average_dom_token_len(url),\n",
    "        \"url_domain_len\": url_domain_len(url),\n",
    "        \"url_hostname_len\": url_hostname_len(url),\n",
    "        \"url_num_dots\": url_num_dots(url),\n",
    "        \"url_num_underscores\": url_num_underscores(url),\n",
    "        \"url_num_equals\": url_num_equals(url),\n",
    "        \"url_num_slashes\": url_num_slashes(url),\n",
    "        \"url_num_dash\": url_num_dash(url),\n",
    "        \"url_num_semicolon\": url_num_semicolon(url),\n",
    "        \"url_num_at\": url_num_at(url),\n",
    "        \"url_num_percent\": url_num_percent(url),\n",
    "        \"url_num_plus\": url_num_plus(url),\n",
    "        \"url_query_len\": url_query_len(url),\n",
    "        \"url_num_query_para\": url_num_query_para(url),\n",
    "        \"url_ip_present\": url_ip_present(url),\n",
    "        \"url_entropy\": url_entropy(url),\n",
    "        \"url_count_consonants\": url_count_consonants(url),\n",
    "        \"url_num_digits\": url_num_digits(url),\n",
    "        \"url_chinese_present\": url_chinese_present(url),\n",
    "        \"url_port\": url_port(url),\n",
    "        \"url_has_https\": url_has_https(url),\n",
    "        \"url_has_ip_address\": url_has_ip_address(url),\n",
    "        \"url_num_subdomains\": url_num_subdomains(url),\n",
    "        \"url_has_suspicious_words\": url_has_suspicious_words(url),\n",
    "        \"url_length_category\": url_length_category(url),\n",
    "        \"url_has_port_in_url\": url_has_port_in_url(url),\n",
    "        \"url_num_special_chars\": url_num_special_chars(url),\n",
    "        \"url_num_params\": url_num_params(url),\n",
    "        \"url_num_fragments\": url_num_fragments(url),\n",
    "        \"url_starts_with_www\": url_starts_with_www(url),\n",
    "        \"url_is_shortened\": url_is_shortened(url),\n",
    "        \"url_has_email\": url_has_email(url),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca2f47",
   "metadata": {},
   "source": [
    "✅ HTML 태그 특성 추출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3649cd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼 목록: ['url', 'html_code', 'repu']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5512.87it/s]\n",
      " 55%|█████▌    | 550/1000 [00:18<00:20, 21.56it/s]c:\\Users\\user\\anaconda3\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "100%|██████████| 1000/1000 [00:34<00:00, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 처리 완료: Benign HTML processed.csv 저장됨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(10**7)  # 10MB로 제한 늘리기\n",
    "\n",
    "tqdm.pandas()  # tqdm 설정 (진행상황 보기)\n",
    "\n",
    "# 📌 1. HTML 태그 특성 추출 함수\n",
    "def extract_html_features(html):\n",
    "    soup = BeautifulSoup(str(html), 'html.parser')\n",
    "    \n",
    "    tags_to_count = [\n",
    "        'iframe', 'script', 'embed', 'object', 'div', 'head', 'body',\n",
    "        'form', 'a', 'small', 'span', 'input', 'applet', 'img', 'video', 'audio'\n",
    "    ]\n",
    "    \n",
    "    features = {}\n",
    "    for tag in tags_to_count:\n",
    "        features[f\"html_num_tags('{tag}')\"] = len(soup.find_all(tag))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 📌 2. CSV 파일 불러오기\n",
    "# html_path = \".html\"  # 실제 HTML 파일 경로로 수정 필요\n",
    "# with open(html_path, encoding=\"utf-8\") as f:\n",
    "#     html_code = f.read()\n",
    "\n",
    "# df_html = pd.DataFrame({\n",
    "#     'html_code': [html_code],\n",
    "#     'repu': ['benign']\n",
    "# })\n",
    "# df_html.to_csv('Feature Website2.csv', index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_csv('benign_html.csv',encoding='utf-8', engine='python')\n",
    "\n",
    "# 컬럼명 확인\n",
    "print(\"컬럼 목록:\", df.columns.tolist())\n",
    "# URL 특성 추출\n",
    "url_feature_df = df['url'].progress_apply(lambda x: pd.Series(extract_url_features(x)))\n",
    "# 📌 3. HTML 특성 추출\n",
    "html_feature_df = df['html_code'].progress_apply(lambda x: pd.Series(extract_html_features(x)))\n",
    "\n",
    "# 📌 4. label 컬럼 (정답)만 따로 떼어내기\n",
    "label_col = 'repu'  # 실제 정답 컬럼 이름에 맞게 수정 필요\n",
    "if label_col not in df.columns:\n",
    "    raise ValueError(f\"정답 컬럼명 '{label_col}'이 존재하지 않습니다. 실제 이름을 확인해 주세요.\")\n",
    "\n",
    "label_df = df[[label_col]]\n",
    "\n",
    "# 📌 5. 최종 결과 결합\n",
    "result_df = pd.concat([url_feature_df, html_feature_df, label_df], axis=1)\n",
    "\n",
    "# 📌 6. 저장\n",
    "result_df.to_csv('Benign HTML processed.csv', index=False)\n",
    "print(\"✅ 처리 완료: Benign HTML processed.csv 저장됨\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d293e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 컬럼 채우기 완료. 총 컬럼 수: 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>url_num_hyphens_dom</th>\n",
       "      <th>url_num_dom_token</th>\n",
       "      <th>url_path_len</th>\n",
       "      <th>url_filename_len</th>\n",
       "      <th>url_longest_dom_token_len</th>\n",
       "      <th>url_average_dom_token_len</th>\n",
       "      <th>url_tld</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>url_hostname_len</th>\n",
       "      <th>...</th>\n",
       "      <th>html_num_tags('a')</th>\n",
       "      <th>html_num_tags('small')</th>\n",
       "      <th>html_num_tags('span')</th>\n",
       "      <th>html_num_tags('input')</th>\n",
       "      <th>html_num_tags('applet')</th>\n",
       "      <th>html_num_tags('img')</th>\n",
       "      <th>html_num_tags('video')</th>\n",
       "      <th>html_num_tags('audio')</th>\n",
       "      <th>repu</th>\n",
       "      <th>Result_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>fr</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>benign</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  url_num_hyphens_dom  url_num_dom_token  url_path_len  \\\n",
       "0       25                    0                  3             1   \n",
       "\n",
       "   url_filename_len  url_longest_dom_token_len  url_average_dom_token_len  \\\n",
       "0                 0                          9                   4.666667   \n",
       "\n",
       "  url_tld  url_domain_len  url_hostname_len  ...  html_num_tags('a')  \\\n",
       "0      fr              16                16  ...                   7   \n",
       "\n",
       "   html_num_tags('small')  html_num_tags('span')  html_num_tags('input')  \\\n",
       "0                       0                     28                       3   \n",
       "\n",
       "   html_num_tags('applet')  html_num_tags('img')  html_num_tags('video')  \\\n",
       "0                        0                     1                       0   \n",
       "\n",
       "   html_num_tags('audio')    repu  Result_v1  \n",
       "0                       0  benign     benign  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📌 1. 필요한 컬럼 목록 정의\n",
    "required_columns = [\n",
    "    'url_len', 'url_num_hyphens_dom', 'url_num_dom_token',\n",
    "    'url_path_len', 'url_filename_len', 'url_longest_dom_token_len',\n",
    "    'url_average_dom_token_len', 'url_domain_len',\n",
    "    'url_hostname_len', 'url_num_dots', 'url_num_underscores',\n",
    "    'url_num_equals', 'url_num_slashes', 'url_num_dash',\n",
    "    'url_num_semicolon', 'url_num_at', 'url_num_percent', 'url_num_plus',\n",
    "    'url_query_len', 'url_num_query_para', 'url_ip_present', 'url_entropy',\n",
    "    'url_count_consonants', 'url_num_digits', 'url_chinese_present',\n",
    "    'url_port','url_has_https', 'url_has_ip_address', 'url_num_subdomains',\n",
    "    'url_has_suspicious_words', 'url_length_category',\n",
    "    'url_has_port_in_url', 'url_num_special_chars', 'url_num_params', 'url_num_fragments', 'url_starts_with_www', 'url_is_shortened', 'url_has_email',\"html_num_tags('iframe')\", \"html_num_tags('script')\",\n",
    "    \"html_num_tags('embed')\", \"html_num_tags('object')\",\n",
    "    \"html_num_tags('div')\", \"html_num_tags('head')\",\n",
    "    \"html_num_tags('body')\", \"html_num_tags('form')\", \"html_num_tags('a')\",\n",
    "    \"html_num_tags('small')\", \"html_num_tags('span')\",\n",
    "    \"html_num_tags('input')\", \"html_num_tags('applet')\",\n",
    "    \"html_num_tags('img')\", \"html_num_tags('video')\",\n",
    "    \"html_num_tags('audio')\"\n",
    "]\n",
    "\n",
    "# 📌 2. 파일 불러오기\n",
    "df = pd.read_csv('Feature Website2 HTML Processed.csv')\n",
    "\n",
    "# 'repu' 컬럼을 복사해 'Result_v1' 컬럼 생성 (복사이므로 'repu'는 그대로 유지)\n",
    "df['Result_v1'] = df['repu']\n",
    "\n",
    "# 'Result_v1' 컬럼을 맨 오른쪽으로 이동\n",
    "col = df.pop('Result_v1')\n",
    "df['Result_v1'] = col\n",
    "\n",
    "\n",
    "\n",
    "# 📌 3. 없는 컬럼 찾아서 0으로 채워 넣기\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "        print(f\"⚠️ 누락된 컬럼 추가됨: {col}\")\n",
    "\n",
    "# 📌 4. 결과 저장 (선택사항)\n",
    "# df.to_csv('Feature Website Final.csv', index=False)\n",
    "\n",
    "# 📌 5. 확인\n",
    "print(\"✅ 컬럼 채우기 완료. 총 컬럼 수:\", len(df.columns))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699f4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url_len', 'url_num_hyphens_dom', 'url_num_dom_token', 'url_path_len',\n",
       "       'url_filename_len', 'url_longest_dom_token_len',\n",
       "       'url_average_dom_token_len', 'url_tld', 'url_domain_len',\n",
       "       'url_hostname_len', 'url_num_dots', 'url_num_underscores',\n",
       "       'url_num_equals', 'url_num_slashes', 'url_num_dash',\n",
       "       'url_num_semicolon', 'url_num_at', 'url_num_percent', 'url_num_plus',\n",
       "       'url_query_len', 'url_num_query_para', 'url_ip_present', 'url_entropy',\n",
       "       'url_count_consonants', 'url_num_digits', 'url_chinese_present',\n",
       "       'url_port', 'url_has_https', 'url_has_ip_address', 'url_num_subdomains',\n",
       "       'url_has_suspicious_words', 'url_length_category',\n",
       "       'url_has_port_in_url', 'url_num_special_chars', 'url_num_params',\n",
       "       'url_num_fragments', 'url_starts_with_www', 'url_is_shortened',\n",
       "       'url_has_email', 'html_num_tags('iframe')', 'html_num_tags('script')',\n",
       "       'html_num_tags('embed')', 'html_num_tags('object')',\n",
       "       'html_num_tags('div')', 'html_num_tags('head')',\n",
       "       'html_num_tags('body')', 'html_num_tags('form')', 'html_num_tags('a')',\n",
       "       'html_num_tags('small')', 'html_num_tags('span')',\n",
       "       'html_num_tags('input')', 'html_num_tags('applet')',\n",
       "       'html_num_tags('img')', 'html_num_tags('video')',\n",
       "       'html_num_tags('audio')', 'repu', 'Result_v1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
