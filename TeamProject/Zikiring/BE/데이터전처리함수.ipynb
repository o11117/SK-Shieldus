{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ea35a9",
   "metadata": {},
   "source": [
    "1. URL ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ë“¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8af915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import socket\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "from collections import Counter\n",
    "\n",
    "def url_len(url):\n",
    "    return len(url)\n",
    "\n",
    "def url_num_hyphens_dom(url):\n",
    "    return urlparse(url).netloc.count('-')\n",
    "\n",
    "def url_num_dom_token(url):\n",
    "    return len(urlparse(url).netloc.split('.'))\n",
    "\n",
    "def url_path_len(url):\n",
    "    return len(urlparse(url).path)\n",
    "\n",
    "def url_filename_len(url):\n",
    "    return len(urlparse(url).path.split('/')[-1])\n",
    "\n",
    "def url_longest_dom_token_len(url):\n",
    "    tokens = urlparse(url).netloc.split('.')\n",
    "    return max(len(t) for t in tokens)\n",
    "\n",
    "def url_average_dom_token_len(url):\n",
    "    tokens = urlparse(url).netloc.split('.')\n",
    "    return sum(len(t) for t in tokens) / len(tokens)\n",
    "\n",
    "def url_domain_len(url):\n",
    "    return len(urlparse(url).netloc)\n",
    "\n",
    "def url_hostname_len(url):\n",
    "    return len(urlparse(url).hostname or '')\n",
    "\n",
    "def url_num_dots(url):\n",
    "    return url.count('.')\n",
    "\n",
    "def url_num_underscores(url):\n",
    "    return url.count('_')\n",
    "\n",
    "def url_num_equals(url):\n",
    "    return url.count('=')\n",
    "\n",
    "def url_num_slashes(url):\n",
    "    return url.count('/')\n",
    "\n",
    "def url_num_dash(url):\n",
    "    return url.count('-')\n",
    "\n",
    "def url_num_semicolon(url):\n",
    "    return url.count(';')\n",
    "\n",
    "def url_num_at(url):\n",
    "    return url.count('@')\n",
    "\n",
    "def url_num_percent(url):\n",
    "    return url.count('%')\n",
    "\n",
    "def url_num_plus(url):\n",
    "    return url.count('+')\n",
    "\n",
    "def url_query_len(url):\n",
    "    return len(urlparse(url).query)\n",
    "\n",
    "def url_num_query_para(url):\n",
    "    return len(urlparse(url).query.split('&')) if urlparse(url).query else 0\n",
    "\n",
    "def url_ip_present(url):\n",
    "    try:\n",
    "        host = urlparse(url).netloc\n",
    "        socket.inet_aton(host)\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def url_entropy(url):\n",
    "    prob = [n / len(url) for n in Counter(url).values()]\n",
    "    return -sum(p * math.log2(p) for p in prob)\n",
    "\n",
    "def url_count_consonants(url):\n",
    "    consonants = set(\"bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ\")\n",
    "    return sum(1 for c in url if c in consonants)\n",
    "\n",
    "def url_num_digits(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "def url_chinese_present(url):\n",
    "    \"\"\"URLì— ì¤‘êµ­ì–´(í•œì) ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    for char in url:\n",
    "        if '\\u4e00' <= char <= '\\u9fff':  # í•œì ìœ ë‹ˆì½”ë“œ ë²”ìœ„\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def url_port(url):\n",
    "    return urlparse(url).port or 80  # ê¸°ë³¸ í¬íŠ¸ 80\n",
    "\n",
    "def url_has_https(url):\n",
    "    \"\"\"HTTPS ì‚¬ìš© ì—¬ë¶€\"\"\"\n",
    "    return int(urlparse(url).scheme == 'https')\n",
    "\n",
    "def url_has_ip_address(url):\n",
    "    \"\"\"ë„ë©”ì¸ ëŒ€ì‹  IP ì‚¬ìš© ì—¬ë¶€\"\"\"\n",
    "    import re\n",
    "    host = urlparse(url).netloc\n",
    "    # IPv4 ì •ê·œì‹\n",
    "    return int(bool(re.match(r\"^\\d{1,3}(\\.\\d{1,3}){3}$\", host)))\n",
    "\n",
    "def url_num_subdomains(url):\n",
    "    \"\"\"ì„œë¸Œë„ë©”ì¸ ê°œìˆ˜\"\"\"\n",
    "    tokens = urlparse(url).hostname.split('.') if urlparse(url).hostname else []\n",
    "    # ì¼ë°˜ì ìœ¼ë¡œ ë„ë©”ì¸+TLDë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ê°€ ì„œë¸Œë„ë©”ì¸\n",
    "    return max(len(tokens) - 2, 0)\n",
    "\n",
    "def url_has_suspicious_words(url):\n",
    "    \"\"\"ì˜ì‹¬ ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ (ì˜ˆ: login, verify, update ë“±)\"\"\"\n",
    "    suspicious = ['login', 'verify', 'update', 'secure', 'account', 'bank', 'signin', 'wp-admin']\n",
    "    return int(any(word in url.lower() for word in suspicious))\n",
    "\n",
    "def url_length_category(url):\n",
    "    \"\"\"URL ê¸¸ì´ êµ¬ê°„í™” (ì§§ìŒ/ë³´í†µ/ê¹€)\"\"\"\n",
    "    l = len(url)\n",
    "    if l < 54:\n",
    "        return 0  # ì§§ìŒ\n",
    "    elif l < 75:\n",
    "        return 1  # ë³´í†µ\n",
    "    else:\n",
    "        return 2  # ê¹€\n",
    "\n",
    "def url_has_port_in_url(url):\n",
    "    \"\"\"URLì— í¬íŠ¸ ëª…ì‹œ ì—¬ë¶€\"\"\"\n",
    "    return int(':' in urlparse(url).netloc)\n",
    "\n",
    "def url_num_special_chars(url):\n",
    "    \"\"\"íŠ¹ìˆ˜ë¬¸ì ê°œìˆ˜\"\"\"\n",
    "    special_chars = set('!#$%^&*()[]{};:,<>?\\\\|`~')\n",
    "    return sum(1 for c in url if c in special_chars)\n",
    "\n",
    "def url_num_params(url):\n",
    "    \"\"\"URL íŒŒë¼ë¯¸í„° ê°œìˆ˜\"\"\"\n",
    "    return urlparse(url).query.count('=')  # íŒŒë¼ë¯¸í„° ê°œìˆ˜\n",
    "\n",
    "def url_num_fragments(url):\n",
    "    \"\"\"URLì— #fragment ê°œìˆ˜\"\"\"\n",
    "    return url.count('#')\n",
    "\n",
    "def url_starts_with_www(url):\n",
    "    \"\"\"wwwë¡œ ì‹œì‘í•˜ëŠ”ì§€ ì—¬ë¶€\"\"\"\n",
    "    return int(urlparse(url).netloc.startswith('www.'))\n",
    "\n",
    "def url_is_shortened(url):\n",
    "    \"\"\"ë‹¨ì¶• URL ì—¬ë¶€ (ì¼ë¶€ ìœ ëª… ë‹¨ì¶• ë„ë©”ì¸ í¬í•¨)\"\"\"\n",
    "    shorteners = ['bit.ly', 'goo.gl', 't.co', 'tinyurl.com', 'ow.ly', 'is.gd', 'buff.ly', 'adf.ly']\n",
    "    netloc = urlparse(url).netloc.lower()\n",
    "    return int(any(s in netloc for s in shorteners))\n",
    "\n",
    "def url_has_email(url):\n",
    "    \"\"\"URLì— ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨ ì—¬ë¶€\"\"\"\n",
    "    return int(bool(re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", url)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba5539",
   "metadata": {},
   "source": [
    "âœ… 2. HTML íƒœê·¸ ê´€ë ¨ íŠ¹ì„± ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e73fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bs4\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_num_tags(html, tag):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return len(soup.find_all(tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783289ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_features(url):\n",
    "    return {\n",
    "        \"url_len\": url_len(url),\n",
    "        \"url_num_hyphens_dom\": url_num_hyphens_dom(url),\n",
    "        \"url_num_dom_token\": url_num_dom_token(url),\n",
    "        \"url_path_len\": url_path_len(url),\n",
    "        \"url_filename_len\": url_filename_len(url),\n",
    "        \"url_longest_dom_token_len\": url_longest_dom_token_len(url),\n",
    "        \"url_average_dom_token_len\": url_average_dom_token_len(url),\n",
    "        \"url_domain_len\": url_domain_len(url),\n",
    "        \"url_hostname_len\": url_hostname_len(url),\n",
    "        \"url_num_dots\": url_num_dots(url),\n",
    "        \"url_num_underscores\": url_num_underscores(url),\n",
    "        \"url_num_equals\": url_num_equals(url),\n",
    "        \"url_num_slashes\": url_num_slashes(url),\n",
    "        \"url_num_dash\": url_num_dash(url),\n",
    "        \"url_num_semicolon\": url_num_semicolon(url),\n",
    "        \"url_num_at\": url_num_at(url),\n",
    "        \"url_num_percent\": url_num_percent(url),\n",
    "        \"url_num_plus\": url_num_plus(url),\n",
    "        \"url_query_len\": url_query_len(url),\n",
    "        \"url_num_query_para\": url_num_query_para(url),\n",
    "        \"url_ip_present\": url_ip_present(url),\n",
    "        \"url_entropy\": url_entropy(url),\n",
    "        \"url_count_consonants\": url_count_consonants(url),\n",
    "        \"url_num_digits\": url_num_digits(url),\n",
    "        \"url_chinese_present\": url_chinese_present(url),\n",
    "        \"url_port\": url_port(url),\n",
    "        \"url_has_https\": url_has_https(url),\n",
    "        \"url_has_ip_address\": url_has_ip_address(url),\n",
    "        \"url_num_subdomains\": url_num_subdomains(url),\n",
    "        \"url_has_suspicious_words\": url_has_suspicious_words(url),\n",
    "        \"url_length_category\": url_length_category(url),\n",
    "        \"url_has_port_in_url\": url_has_port_in_url(url),\n",
    "        \"url_num_special_chars\": url_num_special_chars(url),\n",
    "        \"url_num_params\": url_num_params(url),\n",
    "        \"url_num_fragments\": url_num_fragments(url),\n",
    "        \"url_starts_with_www\": url_starts_with_www(url),\n",
    "        \"url_is_shortened\": url_is_shortened(url),\n",
    "        \"url_has_email\": url_has_email(url),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca2f47",
   "metadata": {},
   "source": [
    "âœ… HTML íƒœê·¸ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3649cd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ ëª©ë¡: ['url', 'html_code', 'repu']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 5512.87it/s]\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 550/1000 [00:18<00:20, 21.56it/s]c:\\Users\\user\\anaconda3\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:34<00:00, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì²˜ë¦¬ ì™„ë£Œ: Benign HTML processed.csv ì €ì¥ë¨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(10**7)  # 10MBë¡œ ì œí•œ ëŠ˜ë¦¬ê¸°\n",
    "\n",
    "tqdm.pandas()  # tqdm ì„¤ì • (ì§„í–‰ìƒí™© ë³´ê¸°)\n",
    "\n",
    "# ğŸ“Œ 1. HTML íƒœê·¸ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_html_features(html):\n",
    "    soup = BeautifulSoup(str(html), 'html.parser')\n",
    "    \n",
    "    tags_to_count = [\n",
    "        'iframe', 'script', 'embed', 'object', 'div', 'head', 'body',\n",
    "        'form', 'a', 'small', 'span', 'input', 'applet', 'img', 'video', 'audio'\n",
    "    ]\n",
    "    \n",
    "    features = {}\n",
    "    for tag in tags_to_count:\n",
    "        features[f\"html_num_tags('{tag}')\"] = len(soup.find_all(tag))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ğŸ“Œ 2. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# html_path = \".html\"  # ì‹¤ì œ HTML íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”\n",
    "# with open(html_path, encoding=\"utf-8\") as f:\n",
    "#     html_code = f.read()\n",
    "\n",
    "# df_html = pd.DataFrame({\n",
    "#     'html_code': [html_code],\n",
    "#     'repu': ['benign']\n",
    "# })\n",
    "# df_html.to_csv('Feature Website2.csv', index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "df = pd.read_csv('benign_html.csv',encoding='utf-8', engine='python')\n",
    "\n",
    "# ì»¬ëŸ¼ëª… í™•ì¸\n",
    "print(\"ì»¬ëŸ¼ ëª©ë¡:\", df.columns.tolist())\n",
    "# URL íŠ¹ì„± ì¶”ì¶œ\n",
    "url_feature_df = df['url'].progress_apply(lambda x: pd.Series(extract_url_features(x)))\n",
    "# ğŸ“Œ 3. HTML íŠ¹ì„± ì¶”ì¶œ\n",
    "html_feature_df = df['html_code'].progress_apply(lambda x: pd.Series(extract_html_features(x)))\n",
    "\n",
    "# ğŸ“Œ 4. label ì»¬ëŸ¼ (ì •ë‹µ)ë§Œ ë”°ë¡œ ë–¼ì–´ë‚´ê¸°\n",
    "label_col = 'repu'  # ì‹¤ì œ ì •ë‹µ ì»¬ëŸ¼ ì´ë¦„ì— ë§ê²Œ ìˆ˜ì • í•„ìš”\n",
    "if label_col not in df.columns:\n",
    "    raise ValueError(f\"ì •ë‹µ ì»¬ëŸ¼ëª… '{label_col}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œ ì´ë¦„ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "label_df = df[[label_col]]\n",
    "\n",
    "# ğŸ“Œ 5. ìµœì¢… ê²°ê³¼ ê²°í•©\n",
    "result_df = pd.concat([url_feature_df, html_feature_df, label_df], axis=1)\n",
    "\n",
    "# ğŸ“Œ 6. ì €ì¥\n",
    "result_df.to_csv('Benign HTML processed.csv', index=False)\n",
    "print(\"âœ… ì²˜ë¦¬ ì™„ë£Œ: Benign HTML processed.csv ì €ì¥ë¨\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d293e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì»¬ëŸ¼ ì±„ìš°ê¸° ì™„ë£Œ. ì´ ì»¬ëŸ¼ ìˆ˜: 57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>url_num_hyphens_dom</th>\n",
       "      <th>url_num_dom_token</th>\n",
       "      <th>url_path_len</th>\n",
       "      <th>url_filename_len</th>\n",
       "      <th>url_longest_dom_token_len</th>\n",
       "      <th>url_average_dom_token_len</th>\n",
       "      <th>url_tld</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>url_hostname_len</th>\n",
       "      <th>...</th>\n",
       "      <th>html_num_tags('a')</th>\n",
       "      <th>html_num_tags('small')</th>\n",
       "      <th>html_num_tags('span')</th>\n",
       "      <th>html_num_tags('input')</th>\n",
       "      <th>html_num_tags('applet')</th>\n",
       "      <th>html_num_tags('img')</th>\n",
       "      <th>html_num_tags('video')</th>\n",
       "      <th>html_num_tags('audio')</th>\n",
       "      <th>repu</th>\n",
       "      <th>Result_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>fr</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>benign</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  url_num_hyphens_dom  url_num_dom_token  url_path_len  \\\n",
       "0       25                    0                  3             1   \n",
       "\n",
       "   url_filename_len  url_longest_dom_token_len  url_average_dom_token_len  \\\n",
       "0                 0                          9                   4.666667   \n",
       "\n",
       "  url_tld  url_domain_len  url_hostname_len  ...  html_num_tags('a')  \\\n",
       "0      fr              16                16  ...                   7   \n",
       "\n",
       "   html_num_tags('small')  html_num_tags('span')  html_num_tags('input')  \\\n",
       "0                       0                     28                       3   \n",
       "\n",
       "   html_num_tags('applet')  html_num_tags('img')  html_num_tags('video')  \\\n",
       "0                        0                     1                       0   \n",
       "\n",
       "   html_num_tags('audio')    repu  Result_v1  \n",
       "0                       0  benign     benign  \n",
       "\n",
       "[1 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ“Œ 1. í•„ìš”í•œ ì»¬ëŸ¼ ëª©ë¡ ì •ì˜\n",
    "required_columns = [\n",
    "    'url_len', 'url_num_hyphens_dom', 'url_num_dom_token',\n",
    "    'url_path_len', 'url_filename_len', 'url_longest_dom_token_len',\n",
    "    'url_average_dom_token_len', 'url_domain_len',\n",
    "    'url_hostname_len', 'url_num_dots', 'url_num_underscores',\n",
    "    'url_num_equals', 'url_num_slashes', 'url_num_dash',\n",
    "    'url_num_semicolon', 'url_num_at', 'url_num_percent', 'url_num_plus',\n",
    "    'url_query_len', 'url_num_query_para', 'url_ip_present', 'url_entropy',\n",
    "    'url_count_consonants', 'url_num_digits', 'url_chinese_present',\n",
    "    'url_port','url_has_https', 'url_has_ip_address', 'url_num_subdomains',\n",
    "    'url_has_suspicious_words', 'url_length_category',\n",
    "    'url_has_port_in_url', 'url_num_special_chars', 'url_num_params', 'url_num_fragments', 'url_starts_with_www', 'url_is_shortened', 'url_has_email',\"html_num_tags('iframe')\", \"html_num_tags('script')\",\n",
    "    \"html_num_tags('embed')\", \"html_num_tags('object')\",\n",
    "    \"html_num_tags('div')\", \"html_num_tags('head')\",\n",
    "    \"html_num_tags('body')\", \"html_num_tags('form')\", \"html_num_tags('a')\",\n",
    "    \"html_num_tags('small')\", \"html_num_tags('span')\",\n",
    "    \"html_num_tags('input')\", \"html_num_tags('applet')\",\n",
    "    \"html_num_tags('img')\", \"html_num_tags('video')\",\n",
    "    \"html_num_tags('audio')\"\n",
    "]\n",
    "\n",
    "# ğŸ“Œ 2. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('Feature Website2 HTML Processed.csv')\n",
    "\n",
    "# 'repu' ì»¬ëŸ¼ì„ ë³µì‚¬í•´ 'Result_v1' ì»¬ëŸ¼ ìƒì„± (ë³µì‚¬ì´ë¯€ë¡œ 'repu'ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)\n",
    "df['Result_v1'] = df['repu']\n",
    "\n",
    "# 'Result_v1' ì»¬ëŸ¼ì„ ë§¨ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™\n",
    "col = df.pop('Result_v1')\n",
    "df['Result_v1'] = col\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ“Œ 3. ì—†ëŠ” ì»¬ëŸ¼ ì°¾ì•„ì„œ 0ìœ¼ë¡œ ì±„ì›Œ ë„£ê¸°\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "        print(f\"âš ï¸ ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€ë¨: {col}\")\n",
    "\n",
    "# ğŸ“Œ 4. ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)\n",
    "# df.to_csv('Feature Website Final.csv', index=False)\n",
    "\n",
    "# ğŸ“Œ 5. í™•ì¸\n",
    "print(\"âœ… ì»¬ëŸ¼ ì±„ìš°ê¸° ì™„ë£Œ. ì´ ì»¬ëŸ¼ ìˆ˜:\", len(df.columns))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699f4aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url_len', 'url_num_hyphens_dom', 'url_num_dom_token', 'url_path_len',\n",
       "       'url_filename_len', 'url_longest_dom_token_len',\n",
       "       'url_average_dom_token_len', 'url_tld', 'url_domain_len',\n",
       "       'url_hostname_len', 'url_num_dots', 'url_num_underscores',\n",
       "       'url_num_equals', 'url_num_slashes', 'url_num_dash',\n",
       "       'url_num_semicolon', 'url_num_at', 'url_num_percent', 'url_num_plus',\n",
       "       'url_query_len', 'url_num_query_para', 'url_ip_present', 'url_entropy',\n",
       "       'url_count_consonants', 'url_num_digits', 'url_chinese_present',\n",
       "       'url_port', 'url_has_https', 'url_has_ip_address', 'url_num_subdomains',\n",
       "       'url_has_suspicious_words', 'url_length_category',\n",
       "       'url_has_port_in_url', 'url_num_special_chars', 'url_num_params',\n",
       "       'url_num_fragments', 'url_starts_with_www', 'url_is_shortened',\n",
       "       'url_has_email', 'html_num_tags('iframe')', 'html_num_tags('script')',\n",
       "       'html_num_tags('embed')', 'html_num_tags('object')',\n",
       "       'html_num_tags('div')', 'html_num_tags('head')',\n",
       "       'html_num_tags('body')', 'html_num_tags('form')', 'html_num_tags('a')',\n",
       "       'html_num_tags('small')', 'html_num_tags('span')',\n",
       "       'html_num_tags('input')', 'html_num_tags('applet')',\n",
       "       'html_num_tags('img')', 'html_num_tags('video')',\n",
       "       'html_num_tags('audio')', 'repu', 'Result_v1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
