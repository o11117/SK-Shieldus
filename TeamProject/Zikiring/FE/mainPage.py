from unittest import result
import streamlit as st
import pymysql
import pandas as pd
from malicious_news import crawl_malicious_news
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
import parsing_html
from parsing_html import getHtml, to_csv, get_csv
import predict_module
from predict_module import predict_from_csv
from sqlalchemy import create_engine
import login
import re
from urllib.parse import urlparse
#st.set_page_config(page_title="ì•…ì„± URL íŒë³„ ì‹œìŠ¤í…œ", layout="wide")

def login_page():
    st.title("ğŸ” ì§€í‚¤ë§ ")
    tab1, tab2 = st.tabs(["ğŸ”“ ë¡œê·¸ì¸", "ğŸ“ íšŒì›ê°€ì…"])

    with tab1:
        st.subheader("ë¡œê·¸ì¸")
        # âœ… ê°€ìš´ë° ì •ë ¬ì„ ìœ„í•´ columns ì‚¬ìš©
        left, center, right = st.columns([2, 3, 2])
        with center:
            username = st.text_input("ì•„ì´ë””", key="login_id")
            password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="login_pw")
            login_clicked = st.button("ë¡œê·¸ì¸")
            if login_clicked:
                success, msg = login.login(username, password)
                if success:
                    st.session_state.logged_in = True
                    st.session_state.user_name = msg.split("ë‹˜")[0]
                    st.session_state.page = "main"
                    st.rerun()
                else:
                    st.error(msg)

    with tab2:
        st.subheader("íšŒì›ê°€ì…")
        left, center, right = st.columns([2, 3, 2])
        with center:
            name = st.text_input("ì´ë¦„", key="signup_name")
            new_username = st.text_input("ì•„ì´ë””", key="signup_id")
            new_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="signup_pw")
            if st.button("íšŒì›ê°€ì…"):
                success, msg = login.signup(name, new_username, new_password)
                if success:
                    st.success(msg)
                else:
                    st.error(msg)


# í•œê¸€í°íŠ¸ path ì„¤ì •
font_path = 'C:\\windows\\Fonts\\malgun.ttf'
font_prop = fm.FontProperties(fname=font_path).get_name()
matplotlib.rc('font', family=font_prop)

def create_table_if_not_exists():
    try:
        conn = pymysql.connect(
            host='localhost',
            port=3306,
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        with conn.cursor() as cursor:
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS feature_and_result (
                    username VARCHAR(100),
                    url_len INT, url_num_hyphens_dom INT, url_num_dom_token INT,
                    url_path_len INT, url_filename_len INT, url_longest_dom_token_len INT,
                    url_average_dom_token_len FLOAT, url_domain_len INT, url_hostname_len INT,
                    url_num_dots INT, url_num_underscores INT, url_num_equals INT,
                    url_num_slashes INT, url_num_dash INT, url_num_semicolon INT,
                    url_num_at INT, url_num_percent INT, url_num_plus INT,
                    url_query_len INT, url_num_query_para INT, url_ip_present INT,
                    url_entropy FLOAT, url_count_consonants INT, url_num_digits INT,
                    url_port INT, url_has_https INT, url_has_ip_address INT,
                    url_num_subdomains INT, url_has_suspicious_words INT,
                    url_length_category INT, url_has_port_in_url INT,
                    url_num_special_chars INT, url_num_params INT, url_num_fragments INT,
                    url_starts_with_www INT, url_is_shortened INT, url_has_email INT,
                    `html_num_tags('iframe')` INT, `html_num_tags('script')` INT,
                    `html_num_tags('embed')` INT, `html_num_tags('object')` INT,
                    `html_num_tags('div')` INT, `html_num_tags('head')` INT,
                    `html_num_tags('body')` INT, `html_num_tags('form')` INT,
                    `html_num_tags('a')` INT, `html_num_tags('small')` INT,
                    `html_num_tags('span')` INT, `html_num_tags('input')` INT,
                    `html_num_tags('applet')` INT, `html_num_tags('img')` INT,
                    `html_num_tags('video')` INT, `html_num_tags('audio')` INT,
                    url TEXT, result INT
                )
            """)
            conn.commit()
    except Exception as e:
        print(f"[DB ì˜¤ë¥˜] í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        conn.close()

#DBì— ê²€ì‚¬í•œ urlì˜ ì´ë¦„ê³¼ feature, resultë¥¼ ì €ì¥
def save_data(user_url, result):
    from sqlalchemy import create_engine

    engine = create_engine('mysql+pymysql://python:python@localhost:3306/python_db')
    connection = None

    try:
        connection = pymysql.connect(
            host='localhost',
            port=3306,
            db='python_db',
            user='python',
            passwd='python',
            charset='utf8'
        )

        with connection.cursor() as cursor:
            sql_check = 'SELECT url FROM feature_and_result WHERE url=%s AND username=%s'
            cursor.execute(sql_check, (user_url, st.session_state.user_name))
            if cursor.fetchone():
                print(f"'{user_url}'ì€(ëŠ”) ì´ë¯¸ DBì— ì¡´ì¬í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return

        df = pd.read_csv('extract_feature.csv')
        df['url'] = user_url
        df['result'] = result
        df['username'] = st.session_state.user_name  # âœ… ì‚¬ìš©ì ì´ë¦„ ì»¬ëŸ¼ ì¶”ê°€

        df.to_sql(name='feature_and_result', con=engine, if_exists='append', index=False)
        print("ë°ì´í„°í”„ë ˆì„ì´ DBì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if connection:
            connection.rollback()
    finally:
        if connection:
            connection.close()

# DBì—ì„œ íŠ¹ì • URLì˜ ì•…ì„± ì—¬ë¶€ ì¡°íšŒ í•¨ìˆ˜
def get_url_result(url):
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        with conn.cursor() as cursor:
            cursor.execute("SELECT result FROM feature_and_result WHERE url = %s", (url,))
            row = cursor.fetchone()
            return row[0] if row else None
    except Exception as e:
        st.error(f"âŒ DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None
    finally:
        conn.close()

# DB ì „ì²´ ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜, ì—¬ê¸°ì„œ url, url_len, url_entropy, resultì´ ì¶œë ¥ë©ë‹ˆë‹¤.
def load_from_DB():
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )

        query = """
            SELECT url, url_len, url_entropy, result
            FROM feature_and_result
            WHERE username = %s
        """

        df = pd.read_sql(query, conn, params=(st.session_state.user_name,))
        return df

    except Exception as e:
        st.error(f"âŒ ì „ì²´ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return pd.DataFrame()
    finally:
        conn.close()

def load_data_from_db(query, params=None):
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        df = pd.read_sql(query, conn, params=params)
        return df
    except Exception as e:
        st.error(f"âŒ DBì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return pd.DataFrame()
    finally:
        conn.close()



def visualize_tag_pie_and_entropy(df):
    try:
        df_temp = df.copy()
        df_temp.columns = df_temp.columns.str.replace("html_num_tags\\('", "", regex=True).str.replace("'\\)", "", regex=True)
        left, center, right = st.columns([2, 4, 2])
        with center:
            st.image("data/URL Entropy Distribution by Class.png", use_column_width=True)

        st.markdown(f'ğŸ§ª URL ì—”íŠ¸ë¡œí”¼ë€? ')
        st.markdown('url ë¬¸ìì—´ì´ ì–¼ë§ˆë‚˜ ë¬´ì‘ìœ„ì ì¸ì§€ ë‚˜íƒ€ë‚´ëŠ” ê°’ì…ë‹ˆë‹¤. í”¼ì‹± ì‚¬ì´íŠ¸ì˜ URLì€ ë¬´ì‘ìœ„ì ì¸ ë¬¸ìì™€ ìˆ«ìë¡œ êµ¬ì„±ë˜ì–´ ì—”íŠ¸ë¡œí”¼ê°’ì´ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.')
        st.markdown('ê²°ê³¼ì ìœ¼ë¡œ, ë†’ì€ ì—”íŠ¸ë¡œí”¼ë¥¼ ê°€ì§„ URLì´ ì •ìƒë³´ë‹¤ ì•…ì„±ì¼ í™•ë¥ ì´ ë” ë†’ìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.')

        # 2. íƒœê·¸ ë¹„ìœ¨ íŒŒì´ ì°¨íŠ¸
        st.markdown(" ")
        st.markdown(f"##### ğŸ” ì•…ì„±/ì •ìƒ ì‚¬ì´íŠ¸ ê°„ íƒœê·¸ ë¹„ìœ¨ ë¹„êµ")

        tags_to_compare = ['script', 'iframe', 'div', 'a', 'img']
        malicious_df_tags = df_temp[df_temp['repu'] == 'malicious']
        benign_df_tags = df_temp[df_temp['repu'] == 'benign']



        # sum ë¨¼ì €, ë³€í™˜ì€ ê·¸ ë‹¤ìŒì—!
        malicious_tag_counts = malicious_df_tags[tags_to_compare].sum()
        benign_tag_counts = benign_df_tags[tags_to_compare].sum()
        malicious_tag_counts = pd.to_numeric(malicious_tag_counts, errors='coerce').fillna(0)
        benign_tag_counts = pd.to_numeric(benign_tag_counts, errors='coerce').fillna(0)
        malicious_df_tags_numeric = malicious_df_tags.drop(columns=['repu']).apply(pd.to_numeric, errors='coerce').fillna(0)
        benign_df_tags_numeric = benign_df_tags.drop(columns=['repu']).apply(pd.to_numeric, errors='coerce').fillna(0)
        malicious_others_count = malicious_df_tags_numeric.sum().sum() - malicious_tag_counts.sum()
        benign_others_count = benign_df_tags_numeric.sum().sum() - benign_tag_counts.sum()

        malicious_final_counts = malicious_tag_counts.to_dict()
        malicious_final_counts['Others'] = malicious_others_count
        benign_final_counts = benign_tag_counts.to_dict()
        benign_final_counts['Others'] = benign_others_count

        # ë¹„ìœ¨ ê¸°ì¤€ ì •ë ¬
        malicious_total = sum(malicious_final_counts.values())
        benign_total = sum(benign_final_counts.values())

        malicious_final_counts = dict(sorted(malicious_final_counts.items(), key=lambda x: x[1], reverse=True))
        benign_final_counts = dict(sorted(benign_final_counts.items(), key=lambda x: x[1], reverse=True))

        fig, axes = plt.subplots(1, 2, figsize=(18, 9))
        colors_mal = sns.color_palette('Set3', n_colors=len(malicious_final_counts))
        colors_ben = sns.color_palette('Pastel1', n_colors=len(benign_final_counts))

        # === ì•…ì„± ì‚¬ì´íŠ¸ ì°¨íŠ¸ ===
        mal_labels = [f"{k}: {v/malicious_total*100:.1f}%" for k, v in malicious_final_counts.items()]
        mal_patches, _ = axes[0].pie(malicious_final_counts.values(), labels=None,
                                    startangle=90, colors=colors_mal, textprops={'fontsize': 12})
        axes[0].set_title('ì•…ì„± ì›¹ì‚¬ì´íŠ¸ì˜ íƒœê·¸ ë¹„ìœ¨', fontsize=16)
        axes[0].axis('equal')
        axes[0].legend(mal_patches, mal_labels, loc='center left', bbox_to_anchor=(1, 0.5), title="HTML íƒœê·¸")

        # === ì •ìƒ ì‚¬ì´íŠ¸ ì°¨íŠ¸ ===
        ben_labels = [f"{k}: {v/benign_total*100:.1f}%" for k, v in benign_final_counts.items()]
        ben_patches, _ = axes[1].pie(benign_final_counts.values(), labels=None,
                                    startangle=90, colors=colors_ben, textprops={'fontsize': 12})
        axes[1].set_title('ì •ìƒ ì›¹ì‚¬ì´íŠ¸ì˜ íƒœê·¸ ë¹„ìœ¨', fontsize=16)
        axes[1].axis('equal')
        axes[1].legend(ben_patches, ben_labels, loc='center left', bbox_to_anchor=(1, 0.5), title="HTML íƒœê·¸")

        plt.tight_layout()
        st.pyplot(fig)
        plt.clf()
        st.markdown(f'ğŸ§ª íŠ¹ì • íƒœê·¸(<script>, <iframe>)ê°€ ê³¼ë„í•˜ê²Œ ë§ê±°ë‚˜ <span>, <link>, <input> ë“±ìœ¼ë¡œ êµ¬ì„±ëœ Othersì˜ ë¹„ìœ¨ì´ ë†’ì€ ê²½ìš° ì•…ì„± ì‚¬ì´íŠ¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
        

    except Exception as e:
        st.error(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

@st.cache_data
def load_train_data(features):
    df_train = pd.read_csv("BE/TrainDataAll.csv")
    df_train.columns = df_train.columns.str.replace(r"html_num_tags\('", "", regex=True).str.replace(r"'\)", "", regex=True)
    df_train = df_train.dropna(subset=features + ['repu'])
    df_train['repu'] = df_train['repu'].astype(str)
    return df_train

def draw_radar_chart(user_url, features):
    try:
        st.markdown(" ")
        st.markdown(f"##### ğŸ” ì…ë ¥ URLê³¼ ì •ìƒ ë° ì•…ì„± URLì˜ í‰ê· ê°’ì„ ë¹„êµí•˜ëŠ” ë ˆì´ë” ì°¨íŠ¸")

        # 1. í•™ìŠµ ë°ì´í„° ê³ ì •ëœ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° + ì •ê·œí™”
        df_train = load_train_data(features)

        # ì •ê·œí™” ê¸°ì¤€ ê³ ì •
        scaler = MinMaxScaler()
        df_train_scaled_values = scaler.fit_transform(df_train[features])
        df_train_scaled = pd.DataFrame(df_train_scaled_values, columns=features)
        df_train_scaled['repu'] = df_train['repu'].values

        # ê³ ì •ëœ í‰ê· ê°’ ê³„ì‚°
        mean_benign = df_train_scaled[df_train_scaled['repu'] == 'benign'][features].mean().values
        mean_malicious = df_train_scaled[df_train_scaled['repu'] == 'malicious'][features].mean().values

        print("âœ” í‰ê·  benign:", mean_benign[:5])
        print("âœ” í‰ê·  malicious:", mean_malicious[:5])


        # 2. DBì—ì„œ ì‚¬ìš©ì ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        user_query = """
            SELECT * FROM feature_and_result
            WHERE url = %s AND username = %s
            LIMIT 1
        """
        df_user = load_data_from_db(user_query, (user_url, st.session_state.get("user_name", "default_user")))

        if df_user.empty:
            st.warning(f"â— `{user_url}` ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")
            return

        df_user.columns = df_user.columns.str.replace(r"html_num_tags\('", "", regex=True).str.replace(r"'\)", "", regex=True)

        # ì‚¬ìš©ì URL ê°’ ì •ê·œí™”
        user_values_raw = df_user[features].iloc[0].values.reshape(1, -1)
        user_values = scaler.transform(user_values_raw).flatten()

        # 3. ë ˆì´ë” ì°¨íŠ¸ ì¤€ë¹„
        labels = features
        num_vars = len(labels)
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]

        user_values = np.concatenate((user_values, [user_values[0]]))
        mean_benign = np.concatenate((mean_benign, [mean_benign[0]]))
        mean_malicious = np.concatenate((mean_malicious, [mean_malicious[0]]))

        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
        ax.plot(angles, user_values, label='ì‚¬ìš©ì URL', color='green')
        ax.plot(angles, mean_benign, label='ì •ìƒ í‰ê· ', color='blue')
        ax.plot(angles, mean_malicious, label='ì•…ì„± í‰ê· ', color='red')

        ax.fill(angles, user_values, color='green', alpha=0.25)
        ax.fill(angles, mean_benign, color='blue', alpha=0.15)
        ax.fill(angles, mean_malicious, color='red', alpha=0.15)

        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(labels, fontsize=9)
        ax.set_title('ì…ë ¥ URL vs ì •ìƒ/ì•…ì„± í‰ê·  Feature ë¹„êµ', size=15)
        ax.legend(loc='upper right')
        
        st.pyplot(fig)

        st.markdown(
            f'ğŸ§ª ì •ìƒ URLê³¼ ì•…ì„± URL í‰ê·  íŒ¨í„´ê³¼ì˜ ì°¨ì´ë¥¼ ë¹„êµí•˜ì—¬, '
            'í˜„ì €íˆ ë‹¤ë¥¸ ì´ìƒì¹˜(Outliers)ê°€ ê´€ì¸¡ë  ê²½ìš° ì´ë¥¼ ì•…ì„± URLë¡œ ë¶„ë¥˜í•˜ëŠ” ê·¼ê±°ê°€ ë©ë‹ˆë‹¤.'
        )

    except Exception as e:
        st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")




def compare_benign_malicious_chart(train_csv_path, features):
    try:
        # === 1. TrainDataì—ì„œ benign í‰ê·  êµ¬í•˜ê¸° ===
        df_train = pd.read_csv(train_csv_path)
        df_train.columns = df_train.columns.str.replace(r"html_num_tags\('", "", regex=True).str.replace(r"'\)", "", regex=True)
        df_train = df_train.dropna(subset=features + ['repu'])

        scaler = MinMaxScaler()
        df_train_scaled_values = scaler.fit_transform(df_train[features])
        df_train_scaled = pd.DataFrame(df_train_scaled_values, columns=features)
        df_train_scaled['repu'] = df_train['repu'].values

        mean_benign = df_train_scaled[df_train_scaled['repu'] == 'benign'][features].mean().values
        mean_malicious = df_train_scaled[df_train_scaled['repu'] == 'malicious'][features].mean().values
        print(f'mean_benign: {df_train_scaled[df_train_scaled['repu'] == 'benign'][features]}')
        print(f'mean_malicious: {df_train_scaled[df_train_scaled['repu'] == 'malicious'][features]}')

        st.markdown(" ")
        st.markdown(f"##### ğŸ” ì•…ì„± ì‚¬ì´íŠ¸ì˜ í‰ê· ê³¼ ì •ìƒ ì‚¬ì´íŠ¸ì˜ í‰ê· ì„ ë¹„êµí•œ ë ˆì´ë” ì°¨íŠ¸")
        # === 3. ë ˆì´ë” ì°¨íŠ¸ ì¤€ë¹„ ===
        labels = features
        num_vars = len(labels)
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]

        mean_malicious = np.concatenate((mean_malicious, [mean_malicious[0]]))
        mean_benign = np.concatenate((mean_benign, [mean_benign[0]]))

        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
        ax.plot(angles, mean_malicious, label='ì•…ì„± ì‚¬ì´íŠ¸ í‰ê· ', color='red')
        ax.plot(angles, mean_benign, label='ì •ìƒ ì‚¬ì´íŠ¸ í‰ê· ', color='blue')
        ax.fill(angles, mean_malicious, color='red', alpha=0.25)
        ax.fill(angles, mean_benign, color='blue', alpha=0.15)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(labels, fontsize=9)
        ax.set_title('ì•…ì„± í‰ê·  vs ì •ìƒ í‰ê·  Feature ë¹„êµ', size=15)
        ax.legend(loc='upper right')
        left, center, right = st.columns([2, 4, 2])
        with center:
            st.pyplot(fig)
        
        st.markdown(f'ğŸ§ª ì•…ì„± ì‚¬ì´íŠ¸ëŠ” url_entropy, ë„ë©”ì¸ ê¸¸ì´, í˜¸ìŠ¤íŠ¸ ê¸¸ì´, ë„ë©”ì¸ í† í° ê¸¸ì´ ë“±ì˜ ê°’ì´ ë†’ì•„ ì „ë°˜ì ìœ¼ë¡œ URLì´ ë³µì¡í•˜ê³  ë¬´ì‘ìœ„ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” ë°˜ë©´, ì •ìƒ ì‚¬ì´íŠ¸ëŠ” wwwë¡œ ì‹œì‘í•  ê°€ëŠ¥ì„±ì´ ë†’ê³ , ë¹„êµì  ì •ì œëœ URL êµ¬ì¡°ë¥¼ ê°–ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.')   
    
    except Exception as e:
        st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def url_analysis_page(train_csv, user_csv, features):
    st.title("ğŸ” URL ë¶„ì„")
    left, center, right = st.columns([2, 4, 2])
    with center:
        user_url = st.text_input("ğŸ” ì•…ì„± ì—¬ë¶€ë¥¼ í™•ì¸í•  URLì„ ì…ë ¥í•˜ì„¸ìš”", "")
        search_button = st.button("ê²€ìƒ‰")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'result' not in st.session_state:
            st.session_state.result = None
        if 'prob' not in st.session_state:
            st.session_state.prob = None
        if 'show_charts' not in st.session_state:
            st.session_state.show_charts = False
        
        # 'ê²€ìƒ‰' ë²„íŠ¼ í´ë¦­ ì‹œ URL ë¶„ì„ ë° ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
        if search_button:
            # URL ë¶„ì„ ë¡œì§
            parsing_html.get_csv(user_url)
            st.session_state.result, st.session_state.prob = predict_module.predict_from_csv(csv_path='extract_feature.csv')
            st.session_state.user_url = user_url
            
            # 'ê²€ìƒ‰' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì°¨íŠ¸ ìˆ¨ê¸°ê¸° ìƒíƒœë¡œ ì´ˆê¸°í™”
            st.session_state.show_charts = False
            
            # DBì— ë°ì´í„° ì €ì¥
            save_data(user_url, st.session_state.result) 

        # ê²°ê³¼ê°€ ì¡´ì¬í•˜ë©´ í‘œì‹œ
        if st.session_state.result is not None:
            if st.session_state.result == 1:
                st.success(f"### âœ… {st.session_state.user_url} ì‚¬ì´íŠ¸ëŠ” **ì •ìƒ ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**\n### í™•ë¥ : {st.session_state.prob:.2f}%")
            elif st.session_state.result == 0:
                st.error(f"### ğŸš¨ {st.session_state.user_url} ì‚¬ì´íŠ¸ëŠ” **ì•…ì„± ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**\n### í™•ë¥ : {st.session_state.prob:.2f}%")
            else:
                st.info(f"âš ï¸ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ê²°ê³¼ê°’: {st.session_state.result}")

            # âœ… ì°¨íŠ¸ í† ê¸€ ë²„íŠ¼ì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ í›„ì— í‘œì‹œ
            chart_button = st.button("ğŸ“ˆ ì°¨íŠ¸ ë³´ê¸°/ìˆ¨ê¸°ê¸°")
            if chart_button:
                st.session_state.show_charts = not st.session_state.show_charts

            # âœ… ì°¨íŠ¸ ìƒíƒœì— ë”°ë¼ ì‹œê°í™” í‘œì‹œ
            if st.session_state.show_charts and st.session_state.result is not None:
                try:
                    st.markdown("### ğŸ§  í•´ë‹¹ URL ë¶„ì„ ì‹œê°í™”")
                    df = pd.read_csv('extract_feature.csv')
                    df['url'] = st.session_state.user_url
                    matched_row = df

                    if not matched_row.empty:
                        st.markdown(" ")
                        st.markdown(f"##### ğŸ” HTML íƒœê·¸ ë³„ íŒŒì´ì°¨íŠ¸ ë¶„ì„")
                        # 1. HTML íƒœê·¸ íŒŒì´ì°¨íŠ¸
                        html_columns = [col for col in matched_row.columns if "html_num_tags" in col]
                        tag_counts = matched_row.iloc[0][html_columns]
                        tag_counts = pd.to_numeric(tag_counts, errors='coerce')  # ìˆ«ìí˜• ë³€í™˜
                        tag_counts = tag_counts[tag_counts > 0]
                                                
                        if not tag_counts.empty:
                            # ì •ë ¬: ê°’ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
                            tag_counts = tag_counts.sort_values(ascending=False)
                                                    
                            # ì¶”ì¶œëœ íƒœê·¸ëª… (ì˜ˆ: html_num_tags('div') â†’ div)
                            tag_labels = tag_counts.index.str.extract(r"\'(\w+)\'")[0]

                            fig1, ax1 = plt.subplots(figsize=(8, 8))
                                                    
                            # ìƒ‰ìƒ ìë™ ìƒì„±
                            colors = plt.cm.Set3(range(len(tag_counts)))

                            # íŒŒì´ì°¨íŠ¸ ê·¸ë¦¬ê¸° (autopct ì—†ì´)
                            wedges, _ = ax1.pie(tag_counts, labels=None, startangle=90, colors=colors)

                            # ë²”ë¡€ ë¼ë²¨ ìƒì„±: "íƒœê·¸ëª…: í¼ì„¼íŠ¸%"
                            tag_labels = tag_counts.index.str.extract(r"\'(\w+)\'")[0]
                            legend_labels = [f"{tag}: {pct:.1f}%" for tag, pct in zip(tag_labels, tag_counts / tag_counts.sum() * 100)]

                            # ì •ë ¬ëœ ìˆœì„œë¡œ ë²”ë¡€ ì¶œë ¥
                            ax1.legend(wedges, legend_labels, title="HTML íƒœê·¸", loc="center left", bbox_to_anchor=(1, 0.5))

                            ax1.set_title("HTML íƒœê·¸ ë¹„ìœ¨")
                            st.pyplot(fig1)
                            st.markdown(f'ğŸ§­ ì‚¬ìš©ì URLì˜ HTML íƒœê·¸ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ì—¬, ì•…ì„± ì‚¬ì´íŠ¸ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íƒœê·¸ì˜ ê³¼ë„í•œ ì‚¬ìš© ì—¬ë¶€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.')

                        else:
                            st.info("í•´ë‹¹ URLì˜ HTML íƒœê·¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                                                    
                        # 2. URL íŠ¹ì„± ë°”ì°¨íŠ¸
                        st.markdown(f"##### ğŸ” URL ê°’ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„ ")
                        url_columns = [
                            'url_len', 'url_path_len', 'url_filename_len',
                            'url_domain_len', 'url_hostname_len', 'url_entropy',
                            'url_num_dots', 'url_num_slashes', 'url_num_equals'
                        ]
                                                        
                        url_columns_mean = [
                            'URL ì „ì²´ ê¸¸ì´', 'URL ê²½ë¡œ ê¸¸ì´', 'URL íŒŒì¼ ì´ë¦„ì˜ ê¸¸ì´', 'http://ì™€ www.ì„ ì œì™¸í•œ ë„ë©”ì¸ ì´ë¦„ì˜ ê¸¸ì´',
                            'í˜¸ìŠ¤íŠ¸ ì´ë¦„ì˜ ê¸¸ì´', 'url ì—”íŠ¸ë¡œí”¼ (ë³µì¡ë„)', 'URLì— í¬í•¨ëœ ì (.)ì˜ ê°œìˆ˜', 'URLì— í¬í•¨ëœ ìŠ¬ë˜ì‹œ(/)ì˜ ê°œìˆ˜',
                            'URLì— í¬í•¨ëœ ë“±í˜¸(=)ì˜ ê°œìˆ˜'
                        ]
                        row_data = matched_row.iloc[0][url_columns].reset_index()
                        row_data.columns = ['Feature', 'Value']
                        fig2, ax2 = plt.subplots(figsize=(10, 6))
                        sns.barplot(data=row_data, x='Feature', y='Value', palette='Set2', ax=ax2)
                        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)
                        ax2.set_title("URLì— ê´€ë ¨ëœ ê°’ ë¹„êµ")
                        plt.tight_layout()
                        
                        st.pyplot(fig2)
                        for i, (col_name, col_mean) in enumerate(zip(url_columns, url_columns_mean)):
                            st.markdown(f"**{i+1}.** **`{col_name}`** : {col_mean}")
                        
                        st.markdown(" ")
                        st.markdown(f'ğŸ§ª ì•…ì„± URLì€ ì •ìƒì ì¸ URLê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë¯¸ë¬˜í•˜ê²Œ ë‹¤ë¥¸ ë„ë©”ì¸ëª…, ë³µì¡í•œ ê²½ë¡œ, íŠ¹ì • í‚¤ì›Œë“œ ë“±ì„ í†µí•´ ì•…ì„± ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ')
                        st.markdown(" ")
                        
                        draw_radar_chart(st.session_state.user_url, features)

                    else:
                        st.info("âš ï¸ ì…ë ¥í•œ URLì— ëŒ€í•œ ìƒì„¸ ë°ì´í„°ê°€ CSV íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.warning(f"âš ï¸ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    

def history_page(train_csv, user_csv, features):
    st.title("ğŸ“œ URL ë¶„ì„ ì´ë ¥")
    df_history = load_from_DB()

    if 'toggle_states' not in st.session_state:
        st.session_state.toggle_states = {}

    if not df_history.empty:
        df_history['result'] = df_history['result'].map({1: 'ì •ìƒ', 0: 'ì•…ì„±'}).fillna('ë¯¸ë¶„ë¥˜')

        for i, row in df_history.iterrows():
            url = row['url']
            result = row['result']

            # ìƒ‰ìƒ ì„¤ì •
            color = 'green' if result == 'ì •ìƒ' else 'red'

            if url not in st.session_state.toggle_states:
                st.session_state.toggle_states[url] = False

            with st.container():
                cols = st.columns([4, 1, 1])

                cols[0].text(url)
                cols[1].markdown(f"<span style='color:{color}; font-weight:bold'>{result}</span>", unsafe_allow_html=True)

                if cols[2].button("ì¡°íšŒ", key=f"view_{i}"):
                    st.session_state.toggle_states[url] = not st.session_state.toggle_states[url]

                if st.session_state.toggle_states[url]:
                    st.markdown(f"##### ğŸ“Œ ìƒì„¸ ì •ë³´")
                    st.markdown(f"**ğŸ”— URL:** `{url}`")
                    st.markdown(f"- ğŸ”¸ URL ê¸¸ì´ (`url_len`): `{row['url_len']}`")
                    st.markdown(f"- ğŸ”¸ URL ì—”íŠ¸ë¡œí”¼ (`url_entropy`): `{row['url_entropy']:.4f}`")
                    st.markdown(f"- ğŸ”¸ íŒë³„ ê²°ê³¼: `{result}`")

                    if st.button(f"ğŸŒ ë§í¬ ì—´ê¸°", key=f"link_{i}"):
                        if result == 'ì•…ì„±':
                            with st.expander("ğŸš¨ **ê²½ê³ **: ì´ ì‚¬ì´íŠ¸ëŠ” ì•…ì„±ìœ¼ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤. ì •ë§ ì ‘ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", expanded=True):
                                st.markdown(f"[ğŸ”— ë§í¬ ì—´ê¸°]({url})", unsafe_allow_html=True)
                        else:
                            st.markdown(f"[ğŸ”— ë§í¬ ì—´ê¸°]({url})", unsafe_allow_html=True)

                    try:
                        # 1. DBì—ì„œ í•´ë‹¹ URLê³¼ ì‚¬ìš©ìëª…ì— ë§ëŠ” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        query = """
                            SELECT *
                            FROM feature_and_result
                            WHERE url = %s AND username = %s
                            LIMIT 1
                        """
                        params = (url, st.session_state.get("user_name", "default_user"))
                        matched_row = load_data_from_db(query, params)

                        if not matched_row.empty:
                            st.markdown(" ")
                            
                            st.markdown(f"##### ğŸ” HTML íƒœê·¸ ë³„ íŒŒì´ì°¨íŠ¸ ë¶„ì„")

                            html_columns = [col for col in matched_row.columns if "html_num_tags" in col]
                            tag_counts = matched_row.iloc[0][html_columns]
                            tag_counts = pd.to_numeric(tag_counts, errors='coerce')  # ìˆ«ìí˜• ë³€í™˜
                            tag_counts = tag_counts[tag_counts > 0]

                            if not tag_counts.empty:
                                tag_counts = tag_counts.sort_values(ascending=False)
                                tag_labels = tag_counts.index.str.extract(r"\'(\w+)\'")[0]

                                fig1, ax1 = plt.subplots(figsize=(8, 8))
                                colors = plt.cm.Set3(range(len(tag_counts)))
                                wedges, _ = ax1.pie(tag_counts, labels=None, startangle=90, colors=colors)

                                legend_labels = [f"{tag}: {pct:.1f}%" for tag, pct in zip(tag_labels, tag_counts / tag_counts.sum() * 100)]
                                ax1.legend(wedges, legend_labels, title="HTML íƒœê·¸", loc="center left", bbox_to_anchor=(1, 0.5))

                                ax1.set_title("HTML íƒœê·¸ ë¹„ìœ¨")
                                left, center, right = st.columns([2, 4, 2])
                                with center:
                                    st.pyplot(fig1)
                                    st.markdown(f'ğŸ§­ ì‚¬ìš©ì URLì˜ HTML íƒœê·¸ ë¶„í¬ë¥¼ ì‹œê°í™”í•˜ì—¬, ì•…ì„± ì‚¬ì´íŠ¸ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” íƒœê·¸ì˜ ê³¼ë„í•œ ì‚¬ìš© ì—¬ë¶€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.')
                            else:
                                st.info("í•´ë‹¹ URLì˜ HTML íƒœê·¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

                            st.markdown(f"##### ğŸ” URL ê°’ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„ ")
                            url_columns = [
                                'url_len', 'url_path_len', 'url_filename_len',
                                'url_domain_len', 'url_hostname_len', 'url_entropy',
                                'url_num_dots', 'url_num_slashes', 'url_num_equals'
                            ]

                            url_columns_mean = [
                                'URL ì „ì²´ ê¸¸ì´', 'URL ê²½ë¡œ ê¸¸ì´', 'URL íŒŒì¼ ì´ë¦„ì˜ ê¸¸ì´', 'http://ì™€ www.ì„ ì œì™¸í•œ ë„ë©”ì¸ ì´ë¦„ì˜ ê¸¸ì´',
                                'í˜¸ìŠ¤íŠ¸ ì´ë¦„ì˜ ê¸¸ì´', 'url ì—”íŠ¸ë¡œí”¼ (ë³µì¡ë„)', 'URLì— í¬í•¨ëœ ì (.)ì˜ ê°œìˆ˜', 'URLì— í¬í•¨ëœ ìŠ¬ë˜ì‹œ(/)ì˜ ê°œìˆ˜',
                                'URLì— í¬í•¨ëœ ë“±í˜¸(=)ì˜ ê°œìˆ˜'
                            ]

                            row_data = matched_row.iloc[0][url_columns].reset_index()
                            row_data.columns = ['Feature', 'Value']
                            fig2, ax2 = plt.subplots(figsize=(10, 6))
                            sns.barplot(data=row_data, x='Feature', y='Value', palette='Set2', ax=ax2)
                            ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)
                            ax2.set_title("URLì— ê´€ë ¨ëœ ê°’ ë¹„êµ")
                            plt.tight_layout()
                            left, center, right = st.columns([2, 4, 2])
                            with center:
                                st.pyplot(fig2)

                            for i, (col_name, col_mean) in enumerate(zip(url_columns, url_columns_mean)):
                                st.markdown(f"**{i+1}.** **`{col_name}`** : {col_mean}")

                            st.markdown(" ")
                            st.markdown(f'ğŸ§ª ì•…ì„± URLì€ ì •ìƒì ì¸ URLê³¼ ìœ ì‚¬í•˜ì§€ë§Œ ë¯¸ë¬˜í•˜ê²Œ ë‹¤ë¥¸ ë„ë©”ì¸ëª…, ë³µì¡í•œ ê²½ë¡œ, íŠ¹ì • í‚¤ì›Œë“œ ë“±ì„ í†µí•´ ì•…ì„± ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ')
                            st.markdown(" ")
                            left, center, right = st.columns([2, 4, 2])
                            with center:
                                draw_radar_chart(url, features)

                        else:
                            st.info("âš ï¸ í•´ë‹¹ URLì— ëŒ€í•œ ë°ì´í„°ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")

                    except Exception as e:
                        st.warning(f"âš ï¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    else:
        st.info("ì•„ì§ ì €ì¥ëœ URL ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")



        
def dashboard_page(train_csv, features, dftd):
    st.subheader("ğŸ“Š ì•…ì„± vs ì •ìƒ ì‚¬ì´íŠ¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    compare_benign_malicious_chart(train_csv, features)
    visualize_tag_pie_and_entropy(dftd)

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main_page():
    create_table_if_not_exists()
    st.set_page_config(page_title="ì§€í‚¤ë§", layout="wide")

    st.sidebar.title("ì§€í‚¤ë§ ë„¤ë¹„ê²Œì´ì…˜")
    with st.sidebar:
        st.markdown(f"ğŸ‘¤ **{st.session_state.user_name} ë‹˜**")
        if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.logged_in = False
            st.session_state.page = "login"
            st.rerun()

    page = st.sidebar.selectbox(
        "í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        ["URL ë¶„ì„", "ë¶„ì„ ì´ë ¥", "ì•…ì„± vs ì •ìƒ ëŒ€ì‹œë³´ë“œ", "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤"]
    )

    train_csv = "BE/TrainDataAll.csv"
    user_csv = "extract_feature.csv"
    features = [                        
        "url_entropy", "url_path_len", "url_filename_len", "url_longest_dom_token_len",
        "url_average_dom_token_len", "url_domain_len", "url_hostname_len", "url_port",
        "script", "div"
    ]

    if page == "URL ë¶„ì„":
        url_analysis_page(train_csv, user_csv, features)

    elif page == "ë¶„ì„ ì´ë ¥":
        history_page(train_csv, user_csv, features)

    elif page == "ì•…ì„± vs ì •ìƒ ëŒ€ì‹œë³´ë“œ":
        dftd = pd.read_csv(train_csv)
        dftd.columns = dftd.columns.str.replace("html_num_tags\\('", "", regex=True).str.replace("'\\)", "", regex=True)
        dashboard_page(train_csv, features, dftd)

    elif page == "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤":
        st.title("ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤")
        st.write("ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")

        search_query = st.text_input("ë‰´ìŠ¤ ì œëª© ê²€ìƒ‰", "")
        with st.spinner('ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            news = crawl_malicious_news()

        if news:
            filtered_news = [n for n in news if search_query.strip() == "" or search_query.lower() in n['title'].lower()]
            if not filtered_news:
                st.info("ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            for n in filtered_news:
                with st.container():
                    cols = st.columns([1, 4])
                    with cols[0]:
                        if n['img']:
                            st.image(n['img'], width=80)
                    with cols[1]:
                        st.markdown(f"**{n['title']}**")
                        with st.expander("ë³¸ë¬¸ ë³´ê¸°"):
                            import requests
                            from bs4 import BeautifulSoup
                            try:
                                detail = requests.get(n['link'])
                                detail_soup = BeautifulSoup(detail.text, 'html.parser')
                                content = detail_soup.select_one('.con #con')
                                if content:
                                    html = str(content)
                                    st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{html}</div>", unsafe_allow_html=True)
                                else:
                                    og_desc = detail_soup.find('meta', attrs={'property': 'og:description'})
                                    if og_desc and og_desc.get('content'):
                                        st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{og_desc['content']}</div>", unsafe_allow_html=True)
                                    else:
                                        st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                            except Exception:
                                st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        else:
            st.info("ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

def main():
    if 'logged_in' not in st.session_state:
        st.session_state.logged_in = False
    if 'page' not in st.session_state:
        st.session_state.page = "login"

    if st.session_state.logged_in and st.session_state.page == "main":
        main_page()
    else:
        login_page()

if __name__ == "__main__":
    main()
